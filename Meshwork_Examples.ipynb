{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meshwork: linking meshes, skeletons, and annotations\n",
    "\n",
    "There are many ways to describe neuroanatomy. We often work with three of them:\n",
    "* Meshes. Meshes provide high resolution 3d structure of the surface of a cell. This is important for understanding the fine details of a neuron, like how long spines are or how the shape of a bouton.\n",
    "* Skeletons. Skeletons provide a tree-like topological structure of a cell. They make it easy to ask questions about proximal/distalness or branch points, are much faster to compute on, and are the typical way neurons are described in most of neuroscience.\n",
    "* Annotations. Annotations decorate the structure of a neuron and can indicate all sorts of things, from synapses to soma location to the base of an axon.\n",
    "\n",
    "The `Meshwork` class helps work interoperably with these three views of the same neuron and gets rid of a lot of the tedious computation one often needs to do when navigating back and forth between these representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Building a Meshwork object\n",
    "\n",
    "The core of a Meshwork object is, as the name suggests, the mesh. Meshes are one of the fundamental objects in the Connectome Annotation Versioning Engine, and every root id has a unique mesh and can be downloaded through cloudvolume. We call this global version, which is the same for everyone, the *Base Mesh*.\n",
    "\n",
    "However, the Base Mesh often has artifacts that cause problems for analysis. For example, internal structures like vesicles or the nucleus can be segmented separately and have internal mesh vertices or artifacts in across several sections of imagery can cause a continous branch to have a gap. While these don't usually cause obvious problems, they present technical problems. Internal mesh vertices can 'grab' annotations like synapses, and gaps make it impossible to naively compute path distances.\n",
    "\n",
    "Because of this, we need to define a derived mesh that will be used to build continuous skeletonizations and anchor annotations. We call this the *Anchor Mesh*. The Anchor Mesh usually has internal vertices removed and gaps bridged. However, it's important to note that there are choices that go into defining this mesh, and thus it is not a universal object.\n",
    "\n",
    "Building a Meshwork object starts with creating an Anchor Mesh. Here, we filter the original mesh to keep only the vertices in the largest connected component, which is sufficient to clean up the example mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meshparty import meshwork\n",
    "from meshparty import trimesh_io, trimesh_vtk, skeletonize, mesh_filters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the base mesh:\n",
    "\n",
    "oid = 648518346349539789\n",
    "\n",
    "mm = trimesh_io.MeshMeta()\n",
    "mesh_base = mm.mesh(filename=f'meshes/{oid}.h5')\n",
    "\n",
    "# Filter out mesh vertices that are not in the largest connected component\n",
    "in_comp = mesh_filters.filter_largest_component(mesh_base)\n",
    "mesh_anchor = mesh_base.apply_mask(in_comp)\n",
    "\n",
    "# The basic Meshwork takes the anchor mesh\n",
    "nrn = meshwork.Meshwork(mesh_anchor, seg_id=oid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annotations \n",
    "\n",
    "The first useful feature of a Meshwork object is dynamic annotation management. Annotations must be in the form of pandas dataframes. A given annotation has a name, a dataframe, and can be either 'anchored' to the mesh or not. For anchored dataframes, there must be a specified point column name. Each row gets associated with the closest mesh vertex to its point in this column. Unanchored annotations don't have attached mesh vertices, but can be useful for tracking information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_in_df = pd.read_hdf('syn.h5', 'post')\n",
    "nrn.add_annotations('syn_in', syn_in_df, point_column='ctr_pt_position')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotations are found under the `.anno` property. Each annotation can be accessed either as a property or as a dictionary with the name as a key. \n",
    "\n",
    "An annotation has a number of different properties:\n",
    "* .df : A length-n dataframe. Note than an anchored annotation has a new column, `mesh_index`, that specifies the index of the mesh index it is anchored to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.anno.syn_in.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .voxels : An n x 3 array of voxel locations for each annotation point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.anno.syn_in.voxels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .points : An n x 3 array of point locations for each annotation point in the same units as the mesh vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.anno.syn_in.points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .mesh_index : An array of mesh indices for each annotation point. (In fact, this array is actually a MeshIndex, but it can be used like a standard numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.anno.syn_in.mesh_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can use the point property to easily make a visualization of the synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_actor = trimesh_vtk.point_cloud_actor(nrn.anno.syn_in.points, size=800, color=(0.2, 0.9, 0.9))\n",
    "mesh_actor = trimesh_vtk.mesh_actor(nrn.mesh, opacity=1, color=(0.7, 0.7, 0.7))\n",
    "trimesh_vtk.render_actors([mesh_actor, syn_actor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional annotations can keep being added.\n",
    "\n",
    "Here, we want the `soma_pt` annotation to only have the approximate center of the soma, but don't want to link it to any paritcular mesh index. We thus set `anchored=False`. This will keep a mesh index from being computed and prevent any filtering, although voxel and point locations can still be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_out_df = pd.read_hdf('syn.h5', 'pre')\n",
    "soma_df = pd.read_hdf('syn.h5', 'soma')\n",
    "\n",
    "nrn.add_annotations('syn_out', syn_out_df, point_column='ctr_pt_position')\n",
    "nrn.add_annotations('soma_pt', soma_df.query('pt_root_id == @oid').copy(), point_column='pt_position', anchored=False)\n",
    "nrn.anno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masks\n",
    "Boolean masks work on meshwork objects, similar to meshes alone, but in this case they apply to the mesh vertices and annotations together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a mask object for mesh vertices within 30000 nm of a particular synapse\n",
    "close_to_point_mask = mesh_filters.filter_spatial_distance_from_points(nrn.mesh,\n",
    "                                                                       nrn.anno.syn_in.points[10],\n",
    "                                                                       30000)\n",
    "\n",
    "# Apply the mask and visualize the mesh as before (we also show the anchor mesh for comparison)\n",
    "nrn.apply_mask(close_to_point_mask)\n",
    "\n",
    "syn_actor = trimesh_vtk.point_cloud_actor(nrn.anno.syn_in.points, size=800, color=(0.2, 0.9, 0.9))\n",
    "mesh_actor = trimesh_vtk.mesh_actor(nrn.mesh, opacity=1, color=(0.7, 0.7, 0.7))\n",
    "mesh_base_actor = trimesh_vtk.mesh_actor(mesh_anchor, opacity=0.2, color=(0.7, 0.7, 0.7))\n",
    "trimesh_vtk.render_actors([mesh_actor, syn_actor, mesh_base_actor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike meshes, meshwork objects retain the memory of the Anchor Mesh and can always be reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(nrn.anno.syn_in)} input synapses before reset.')\n",
    "nrn.reset_mask()\n",
    "print(f'There are {len(nrn.anno.syn_in)} input synapses after reset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you want to query what annotations are within a given node mask and not change the whole object. We can accomplish this with the `filter_query` function like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nrn.anno.syn_in.filter_query(close_to_point_mask).df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skeletons : Adding directed topology\n",
    "\n",
    "A meshwork class can also build a skeleton from their Anchor Mesh. Much of the utility of a meshwork object comes from being able to link extremely fast skeleton operations like finding a path between two points to mesh structures and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.skeletonize_mesh(soma_pt=nrn.anno.soma_pt.points[0], soma_thresh_distance=8500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mesh now has a `.skeleton` property. For example, we can quickly compute the total cable length of the mesh in microns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.skeleton.path_length()/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it would be confusing for us to always go back and forth between meshes and skeletons. In general, we will stick to dealing with mesh vertices. Inside the Meshwork object the conversion from mesh to skeleton vertices and back again is handled automatically. For example, `nrn.root` returns a mesh index associated with the skeleton root, which here is set to the soma position.\n",
    "\n",
    "Here, let's look at the child nodes of the root, which should be the base of each dendritic and axonal process. For each index, we can ask for the skeleton downstream of that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all children of the root node, which is the soma.\n",
    "branch_starts = nrn.child_index(nrn.root)\n",
    "# Let's just pick one of these\n",
    "mesh_downstream = nrn.downstream_of(branch_starts[2])\n",
    "mesh_downstream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions like `path_length` exist at the meshwork level where they expect mesh indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.path_length(mesh_downstream) / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JointMeshIndex and JointSkeletonIndex\n",
    "\n",
    "You'll note that the type of `mesh_downstream` is not an array, but a `JointMeshIndex`. This is a class that contains methods to convert mesh indices to other representations, such as boolean masks and skeleton indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeshIndices have a number of conversion functions for different situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_mesh_index just returns the same values\n",
    "mesh_downstream.to_mesh_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_mesh_mask returns a boolean mask with True at the location of the indices\n",
    "mesh_downstream.to_mesh_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_skel_index returns the skeleton indices for each. Note: This does not give a 1-1 correspondance between indices.\n",
    "mesh_downstream.to_skel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_skel_index returns the skeleton indices for each. Has a -1 if no map is available for the index.\n",
    "mesh_downstream.to_skel_index_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skeleton indices are like mesh indices, but because there is a 1-to-many mapping between skeleton vertices and mesh vertices they have a few more options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SkeletonIndexs are similar, but for meshes\n",
    "# Let's make one from the downstream values.\n",
    "skinds = np.unique( mesh_downstream.to_skel_index )\n",
    "\n",
    "# to_mesh_index returns the exact mesh index\n",
    "skinds.to_mesh_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_mesh_mask returns the mesh mask for the skeleton indices\n",
    "skinds.to_mesh_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_mesh_region returns a list of MeshIndex arrays for each element of the skeleton indices\n",
    "skinds.to_mesh_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of indices can be converted into a MeshIndex or SkeletonIndex through \n",
    "`nrn.MeshIndex` or `nrn.SkeletonIndex` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minds = nrn.MeshIndex([1,2,3])\n",
    "minds.to_skel_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting operations together\n",
    "As an example, let's look at the synapses per unit length for each branch by going through each branch off the root and computing its total path length and the number of synaptic inputs and outputs on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_in_on_branch = []\n",
    "syn_out_on_branch = []\n",
    "len_of_branch = []\n",
    "\n",
    "branch_starts = nrn.child_index(nrn.root)\n",
    "\n",
    "for bp in branch_starts:\n",
    "    mesh_downstream = nrn.downstream_of(bp)\n",
    "    syn_in_on_branch.append(len(nrn.anno.syn_in.filter_query(mesh_downstream.to_mesh_mask).df))\n",
    "    syn_out_on_branch.append(len(nrn.anno.syn_out.filter_query(mesh_downstream.to_mesh_mask).df))\n",
    "    len_of_branch.append(nrn.path_length(mesh_downstream))\n",
    "\n",
    "syn_in_on_branch = np.array(syn_in_on_branch)\n",
    "syn_out_on_branch = np.array(syn_out_on_branch)\n",
    "len_of_branch = np.array(len_of_branch)/1000  # in microns\n",
    "\n",
    "syn_in_per_micron = syn_in_on_branch/len_of_branch\n",
    "syn_out_per_micron = syn_out_on_branch/len_of_branch\n",
    "\n",
    "pd.DataFrame({'Input density': syn_in_per_micron, 'Output density': syn_out_per_micron})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the branch with the highest density of inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.reset_mask()\n",
    "branch_ind = np.argmax(syn_in_per_micron)\n",
    "mesh_downstream = nrn.downstream_of(branch_starts[branch_ind])\n",
    "syn_points_downstream = nrn.anno.syn_in.filter_query(mesh_downstream.to_mesh_mask).points\n",
    "\n",
    "syn_actor = trimesh_vtk.point_cloud_actor(syn_points_downstream, size=800, color=(0.2, 0.8, 0.8))\n",
    "mesh_actor = trimesh_vtk.mesh_actor(nrn.mesh, opacity=1, color=(0.7, 0.7, 0.7))\n",
    "trimesh_vtk.render_actors([syn_actor, mesh_actor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading and saving\n",
    "\n",
    "We can loading and save the whole meshwork object. Note that it saves the original anchor mesh (*not* the base mesh) and all annotations, but does apply the same mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{nrn.seg_id}_meshwork.h5\"\n",
    "nrn.save_meshwork(filename, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn2 = meshwork.load_meshwork(filename)\n",
    "np.all( nrn.branch_points == nrn2.branch_points )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More skeleton operations\n",
    "\n",
    "In general, operations that consider paths along the neurite or have a sense of distal/proximal have these skeleton-like meshwork functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End points can be accessed like branch points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrn.end_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segments are regions between branch and end points. Here, let's compute them and highlight the segment with the most input synapses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_all_segments and look at two of them\n",
    "mesh_segs = nrn.segments()\n",
    "mesh_segs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count inputs \n",
    "nsyn_in = []\n",
    "for seg in mesh_segs:\n",
    "    nsyn_in.append(len(nrn.anno.syn_in.filter_query(seg.to_mesh_mask).df))\n",
    "\n",
    "clrs = np.array( [(0.3, 0.3, 0.3), (0.8, 0.2, 0.2)] )\n",
    "seg = mesh_segs[np.argmax(nsyn_in)]\n",
    "mesh_colors = clrs[seg.to_mesh_mask.astype(int)]\n",
    "\n",
    "ma = trimesh_vtk.mesh_actor(nrn.mesh, vertex_colors=mesh_colors, opacity=1)\n",
    "trimesh_vtk.render_actors([ma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geodesic distance between mesh vertices along the skeleton is computed with `distance_between`. Here, we compute the distribution of closest distances between output synapses. The `distance_to_root` function is convenient wrapper for finding the distance to the root node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = nrn.distance_between(nrn.anno.syn_out.mesh_index, nrn.anno.syn_out.mesh_index)\n",
    "d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the trivial 0 along the diagonal\n",
    "d_out_nodiag = d_out + np.diag(np.inf*np.ones(len(d_out)))\n",
    "intersynapse_d = np.min(d_out_nodiag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_ = plt.hist(intersynapse_d/1000, bins=np.arange(0,40, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mesh points along the path between mesh points can be computed with `path_between`. Here, we plot synapse sizes as a function of distance to root along a single path from one end point to root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_root = nrn.path_between(nrn.end_points[5], nrn.root)\n",
    "syn_on_path = nrn.anno.syn_in.filter_query(path_to_root.to_mesh_mask)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3), dpi=100)\n",
    "ax.plot(nrn.distance_to_root(syn_on_path.mesh_index)/1000, syn_on_path.df['size'], '.')\n",
    "_ = ax.set_xlabel('Dist to root ($\\mu m)')\n",
    "_ = ax.set_ylabel('Synapse size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the skeleton to split axon/dendrite\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meshparty.meshwork import algorithms\n",
    "\n",
    "is_axon, qual = algorithms.split_axon_by_synapses(nrn, \n",
    "                                                  nrn.anno.syn_in.mesh_index,\n",
    "                                                  nrn.anno.syn_out.mesh_index,\n",
    "                                                  )\n",
    "\n",
    "# split_axon_by_synapses returns a skeleton mask, which we want to convert to a SkeletonIndex \n",
    "is_axon_skel = nrn.SkeletonIndex(np.flatnonzero(is_axon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrs = np.array([[0.7, 0.7, 0.7], [0.8, 0.2, 0.3]])\n",
    "mesh_color = clrs[is_axon_skel.to_mesh_mask.astype(int)]\n",
    "\n",
    "ma = trimesh_vtk.mesh_actor(nrn.mesh, vertex_colors=mesh_color, opacity=1)\n",
    "trimesh_vtk.render_actors([ma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear density\n",
    "\n",
    "This function computes the density of annotations (e.g. synapses) along a moving window across the branches of a neuron, normalized by cable length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us look at linear synapse density only on the dendrites\n",
    "nrn.apply_mask(np.invert(is_axon_skel.to_mesh_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = nrn.linear_density(nrn.anno.syn_in.mesh_index, 2500, normalize=True, exclude_root=True)\n",
    "\n",
    "ma = trimesh_vtk.mesh_actor(nrn.mesh, vertex_colors=(1000*rho-0.5), opacity=1)\n",
    "trimesh_vtk.render_actors([ma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“data_analysis”",
   "language": "python",
   "name": "jupyter_space"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}